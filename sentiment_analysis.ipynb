{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb7d4d2",
   "metadata": {},
   "source": [
    "###### loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30f56cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assuming it's in CSV format)\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb3d91",
   "metadata": {},
   "source": [
    "###### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "350c4790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'sentiment'], dtype='object')\n",
      "(50000, 2)\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "review       object\n",
      "sentiment    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e91f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  one of the other reviewers has mentioned that ...  \n",
      "1  a wonderful little production the filming tech...  \n",
      "2  i thought this was a wonderful way to spend ti...  \n",
      "3  basically theres a family where a little boy j...  \n",
      "4  petter matteis love in the time of money is a ...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the review column\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "\n",
    "# Display the first few cleaned reviews\n",
    "print(df[['review', 'cleaned_review']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9a801",
   "metadata": {},
   "source": [
    "##### tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8bb77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc38779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prave\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ec4ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_review'] = df['cleaned_review'].apply(lambda x: word_tokenize(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "711e2dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cleaned_review  \\\n",
      "0  one of the other reviewers has mentioned that ...   \n",
      "1  a wonderful little production the filming tech...   \n",
      "2  i thought this was a wonderful way to spend ti...   \n",
      "3  basically theres a family where a little boy j...   \n",
      "4  petter matteis love in the time of money is a ...   \n",
      "\n",
      "                                    tokenized_review  \n",
      "0  [one, of, the, other, reviewers, has, mentione...  \n",
      "1  [a, wonderful, little, production, the, filmin...  \n",
      "2  [i, thought, this, was, a, wonderful, way, to,...  \n",
      "3  [basically, theres, a, family, where, a, littl...  \n",
      "4  [petter, matteis, love, in, the, time, of, mon...  \n"
     ]
    }
   ],
   "source": [
    "print(df[['cleaned_review', 'tokenized_review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e868d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd2f5fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prave\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efe79b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b6ad58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    return[word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f8f4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tokens'] = df['tokenized_review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0aa30a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    tokenized_review  \\\n",
      "0  [one, of, the, other, reviewers, has, mentione...   \n",
      "1  [a, wonderful, little, production, the, filmin...   \n",
      "2  [i, thought, this, was, a, wonderful, way, to,...   \n",
      "3  [basically, theres, a, family, where, a, littl...   \n",
      "4  [petter, matteis, love, in, the, time, of, mon...   \n",
      "\n",
      "                                      cleaned_tokens  \n",
      "0  [one, reviewers, mentioned, watching, oz, epis...  \n",
      "1  [wonderful, little, production, filming, techn...  \n",
      "2  [thought, wonderful, way, spend, time, hot, su...  \n",
      "3  [basically, theres, family, little, boy, jake,...  \n",
      "4  [petter, matteis, love, time, money, visually,...  \n"
     ]
    }
   ],
   "source": [
    "print(df[['tokenized_review', 'cleaned_tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc7a89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prave\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cleaned_tokens  \\\n",
      "0  [one, reviewers, mentioned, watching, oz, epis...   \n",
      "1  [wonderful, little, production, filming, techn...   \n",
      "2  [thought, wonderful, way, spend, time, hot, su...   \n",
      "3  [basically, theres, family, little, boy, jake,...   \n",
      "4  [petter, matteis, love, time, money, visually,...   \n",
      "\n",
      "                                   lemmatized_tokens  \n",
      "0  [one, reviewer, mention, watch, oz, episode, y...  \n",
      "1  [wonderful, little, production, film, techniqu...  \n",
      "2  [think, wonderful, way, spend, time, hot, summ...  \n",
      "3  [basically, there, family, little, boy, jake, ...  \n",
      "4  [petter, matteis, love, time, money, visually,...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download the lemmatizer data from NLTK\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to get the part of speech for lemmatization\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Function to apply lemmatization\n",
    "def lemmatize_tokens(tokens):\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    return [lemmatizer.lemmatize(token, get_wordnet_pos(pos_tag)) for token, pos_tag in pos_tags]\n",
    "\n",
    "# Apply the function to lemmatize tokens\n",
    "df['lemmatized_tokens'] = df['cleaned_tokens'].apply(lemmatize_tokens)\n",
    "\n",
    "# Display the first few lemmatized tokens\n",
    "print(df[['cleaned_tokens', 'lemmatized_tokens']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05529681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment', 'cleaned_review', 'tokenized_review',\n",
       "       'cleaned_tokens', 'lemmatized_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcfd9092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 203322)\n"
     ]
    }
   ],
   "source": [
    "# Combine lemmatized tokens into a single string per document\n",
    "df['lemmatized_text'] = df['lemmatized_tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the lemmatized text\n",
    "X = tfidf_vectorizer.fit_transform(df['lemmatized_text'])\n",
    "\n",
    "# Display the shape of the TF-IDF matrix\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81e2c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      5044\n",
      "           1       0.87      0.91      0.89      4956\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ensure 'sentiment' is numerical (if it's not already)\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split data into features and labels\n",
    "X = tfidf_vectorizer.transform(df['lemmatized_text'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Display performance metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb3563cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model and vectorizer\n",
    "with open('sentiment_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(tfidf_vectorizer, vectorizer_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81f966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
